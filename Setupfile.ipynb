{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import re\n",
    "# import hickle as hkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torch.legacy.nn import Reshape\n",
    "# import graphviz\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "#from visualize import make_dot\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize, imread, imshow\n",
    "import cv2\n",
    "import time\n",
    "import logging\n",
    "from math import log,sqrt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from misc import initialize_weights1\n",
    "\n",
    "\n",
    "class _EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=False):\n",
    "        super(_EncoderBlock, self).__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout())\n",
    "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.encode = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encode(x)\n",
    "\n",
    "\n",
    "class _DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(_DecoderBlock, self).__init__()\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, middle_channels, kernel_size=3),\n",
    "            nn.BatchNorm2d(middle_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(middle_channels, middle_channels, kernel_size=3),\n",
    "            nn.BatchNorm2d(middle_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.enc1 = _EncoderBlock(3, 64)\n",
    "        self.enc2 = _EncoderBlock(64, 128)\n",
    "        self.enc3 = _EncoderBlock(128, 256)\n",
    "        self.enc4 = _EncoderBlock(256, 512, dropout=True)\n",
    "        self.center = _DecoderBlock(512, 1024, 512)\n",
    "        self.dec4 = _DecoderBlock(1024, 512, 256)\n",
    "        self.dec3 = _DecoderBlock(512, 256, 128)\n",
    "        self.dec2 = _DecoderBlock(256, 128, 64)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.final = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        initialize_weights1(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        center = self.center(enc4)\n",
    "        dec4 = self.dec4(torch.cat([center, F.upsample(enc4, center.size()[2:], mode='bilinear')], 1))\n",
    "        dec3 = self.dec3(torch.cat([dec4, F.upsample(enc3, dec4.size()[2:], mode='bilinear')], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, F.upsample(enc2, dec3.size()[2:], mode='bilinear')], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, F.upsample(enc1, dec2.size()[2:], mode='bilinear')], 1))\n",
    "        final = self.final(dec1)\n",
    "        x = F.upsample(final, x.size()[2:], mode='bilinear')\n",
    "        x = F.log_softmax(x)\n",
    "#         m = torch.nn.Softmax()\n",
    "#         x = m(x)\n",
    "        #x = x.view(-1,360,480)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(output_batch):\n",
    "    bs,c,h,w = output_batch.size()\n",
    "    tensor = output_batch.data\n",
    "    values, indices = tensor.cpu().max(1)\n",
    "    indices = indices.view(bs,h,w)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_rgb_to_bgr(batch):\n",
    "    #print(batch.size())\n",
    "    (r, g, b) = torch.chunk(batch, 3, 1)\n",
    "    #print(r.size())\n",
    "    batch1 = torch.cat((b, g, r),1)\n",
    "    #print(batch1.size())\n",
    "    return batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"\n",
    "    Normalize an tensor image with mean and standard deviation.\n",
    "    Given mean: (R, G, B) and std: (R, G, B),\n",
    "    will normalize each channel of the torch.*Tensor, i.e.\n",
    "    channel = (channel - mean) / std\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for R, G, B channels respecitvely.\n",
    "        std (sequence): Sequence of standard deviations for R, G, B channels\n",
    "            respecitvely.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        # TODO: make efficient\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hulk-css/New Volume/Deep_Learning/semantic_seg_dataset_creation/misc.py:20: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(module.weight)\n",
      "/home/hulk-css/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/hulk-css/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/hulk-css/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/hulk-css/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:79: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import argparse\n",
    "import sys\n",
    "import scipy.misc\n",
    "\n",
    "######################Weight for Camvid ####################\n",
    "net = UNet(12)\n",
    "net = net.cuda()\n",
    "net.load_state_dict(torch.load(\"UNET_seg_Camvid_epochs_135.pth\"))\n",
    "######################################################################\n",
    "cap = cv2.VideoCapture('0005VD.MXF') \n",
    "count = 0\n",
    "ret=1\n",
    "fourcc1 = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fourcc2 = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "out1 = cv2.VideoWriter('video.avi',fourcc1, 20.0, (480,360))\n",
    "out2 = cv2.VideoWriter('segment.avi',fourcc2, 20.0, (480,360))\n",
    "\n",
    "\n",
    "# out1 = cv2.VideoWriter('output1.avi',fourcc1, 20.0, (480,270))\n",
    "\n",
    "while ret:\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC,count*70)      # Go to the 1 sec. position\n",
    "    ret,frame = cap.read()\n",
    " \n",
    "    if ret:\n",
    "        frame1 = cv2.resize(frame, (480, 360))\n",
    "        R_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        frame = cv2.cvtColor(frame1,cv2.COLOR_BGR2RGB)\n",
    "        frame = Image.fromarray(frame)\n",
    "        \n",
    "        frame = np.array(frame)/255\n",
    "        test = torch.from_numpy(frame).transpose(1,2).transpose(0,1)\n",
    "        \n",
    "        test = np.reshape(test,(1,3,360,480))\n",
    "        test=test.type(torch.FloatTensor)\n",
    "\n",
    "        test_pred = net.forward(Variable(test, volatile=True).cuda())\n",
    "        test_pred=get_predictions(test_pred)\n",
    "        pred = test_pred.cpu()\n",
    "        pred = pred.detach().numpy()\n",
    "        pred = np.reshape(pred,(1,360,480))\n",
    "        pred = pred.transpose(1,2,0)\n",
    "        pred = cv2.resize(pred,(480,360))\n",
    "\n",
    "#         print(pred.shape[0])\n",
    "        for i in range(pred.shape[0]):\n",
    "            for j in range(pred.shape[1]):\n",
    "                R_gray[i][j]=pred[i][j]\n",
    "        col_pred = cv2.applyColorMap(R_gray*70, cv2.COLORMAP_JET)\n",
    "\n",
    "        cv2.imshow('Pred',col_pred)\n",
    "        cv2.imshow('Video',frame1)\n",
    "        out1.write(frame1)\n",
    "        out2.write(col_pred)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    count += 1\n",
    "cap.release()\n",
    "out1.release()\n",
    "out2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hulk-css/New Volume/Deep_Learning/semantic_seg_dataset_creation/misc.py:20: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(module.weight)\n",
      "/home/hulk-css/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/hulk-css/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/hulk-css/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/hulk-css/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:79: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4c21ba0ad26e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_MSEC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# Go to the 1 sec. position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import argparse\n",
    "import sys\n",
    "import scipy.misc\n",
    "\n",
    "######################Weight for CSS####################\n",
    "net = UNet(3)\n",
    "net = net.cuda()\n",
    "net.load_state_dict(torch.load(\"./CSS_weight/UNET_weight_epochs_100.pth\"))\n",
    "###############################################################################\n",
    "\n",
    "cap = cv2.VideoCapture('2.MP4') \n",
    "count = 0\n",
    "ret=1\n",
    "fourcc1 = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fourcc2 = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "out1 = cv2.VideoWriter('video_CSS.avi',fourcc1, 20.0, (480,270))\n",
    "out2 = cv2.VideoWriter('segment_CSS.avi',fourcc2, 20.0, (480,270))\n",
    "\n",
    "\n",
    "# out1 = cv2.VideoWriter('output1.avi',fourcc1, 20.0, (480,270))\n",
    "\n",
    "while ret:\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC,count*100)      # Go to the 1 sec. position\n",
    "    ret,frame = cap.read()\n",
    " \n",
    "    if ret:\n",
    "        frame1 = cv2.resize(frame, (480, 270))\n",
    "        R_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        frame = cv2.cvtColor(frame1,cv2.COLOR_BGR2RGB)\n",
    "        frame = Image.fromarray(frame)\n",
    "        \n",
    "        frame = np.array(frame)/255\n",
    "        test = torch.from_numpy(frame).transpose(1,2).transpose(0,1)\n",
    "        \n",
    "        test = np.reshape(test,(1,3,270,480))\n",
    "        test=test.type(torch.FloatTensor)\n",
    "\n",
    "        test_pred = net.forward(Variable(test, volatile=True).cuda())\n",
    "        test_pred=get_predictions(test_pred)\n",
    "        pred = test_pred.cpu()\n",
    "        pred = pred.detach().numpy()\n",
    "        pred = np.reshape(pred,(1,270,480))\n",
    "        pred = pred.transpose(1,2,0)\n",
    "        pred = cv2.resize(pred,(480,270))\n",
    "\n",
    "#         print(pred.shape[0])\n",
    "        for i in range(pred.shape[0]):\n",
    "            for j in range(pred.shape[1]):\n",
    "                R_gray[i][j]=pred[i][j]\n",
    "        col_pred = cv2.applyColorMap(R_gray*100, cv2.COLORMAP_JET)\n",
    "\n",
    "        cv2.imshow('Pred',col_pred)\n",
    "        cv2.imshow('Video',frame1)\n",
    "        out1.write(frame1)\n",
    "        out2.write(col_pred)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    count += 1\n",
    "cap.release()\n",
    "out1.release()\n",
    "out2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cv2, pafy\n",
    "# url = 'https://www.youtube.com/watch?v=b7BEAsyPgHM'\n",
    "# # vPafy = pafy.new(url)\n",
    "# # play = vPafy.getbest(preftype=\"webm\")\n",
    "# # url = \"https://www.youtube.com/watch?v=aKX8uaoy9c8\"\n",
    "# videoPafy = pafy.new(url)\n",
    "# play = videoPafy.getbest(preftype=\"webm\")\n",
    "\n",
    "#     #start the video\n",
    "# cap = cv2.VideoCapture(play.url)\n",
    "# while (True):\n",
    "#     ret,frame = cap.read()\n",
    "#     print(frame.shape)\n",
    "#     cv2.imshow('frame',frame)\n",
    "#     if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "#         break    \n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import pafy\n",
    "\n",
    "# url = \"https://www.youtube.com/watch?v=b7BEAsyPgHM\"\n",
    "# video = pafy.new(url)\n",
    "# best = video.getbest(preftype=\"mp4\")\n",
    "\n",
    "# capture = cv2.VideoCapture()\n",
    "# capture.open(best.url)\n",
    "\n",
    "# success,image = capture.read()\n",
    "# print(image.shape)\n",
    "\n",
    "# while success:\n",
    "#     cv2.imshow('frame', image)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "#     success,image = capture.read()\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "# capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
